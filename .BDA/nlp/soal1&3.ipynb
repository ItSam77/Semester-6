{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0am9VKP9spi"
      },
      "source": [
        "## SOAL 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlwQ6VEw9PTM",
        "outputId": "78620187-9688-4782-fb5f-628bb5e0dfa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hasil Preprocessing:\n",
            "['perintah', 'indonesia', 'terus', 'upaya', 'tingkat', 'sejahtera', 'rakyat', 'lalu', 'bagai', 'program', 'sosial', 'salah', 'satu', 'fokus', 'utama', 'kurang', 'senjang', 'ekonomi', 'wilayah', 'kota', 'desa', 'program', 'bantu', 'sosial', 'kartu', 'prakerja', 'subsidi', 'didik', 'harap', 'bantu', 'masyarakat', 'kurang', 'mampu']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# 1. Persiapan - Membuat dan membaca file teks\n",
        "paragraph = \"\"\"\n",
        "Pemerintah Indonesia terus berupaya meningkatkan kesejahteraan rakyat melalui berbagai program sosial. 12 % $ 34 ; &* Salah satu fokus utama adalah mengurangi kesenjangan ekonomi antara wilayah perkotaan dan pedesaan. Program seperti bantuan sosial, kartu prakerja, dan subsidi pendidikan diharapkan dapat membantu masyarakat kurang mampu.\n",
        "\"\"\"\n",
        "\n",
        "# Menyimpan ke file teks\n",
        "with open('artikel.txt', 'w', encoding='utf-8') as file:\n",
        "    file.write(paragraph)\n",
        "\n",
        "# Membaca file teks\n",
        "with open('artikel.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# 2. Preprocessing teks\n",
        "# Case folding\n",
        "def case_folding(text):\n",
        "    text = text.lower()  # Mengubah ke lowercase\n",
        "    text = re.sub(r'\\d+', '', text)  # Menghapus angka\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Menghapus tanda baca\n",
        "    text = text.strip()  # Menghapus whitespace di awal dan akhir\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Mengganti multiple whitespace dengan single space\n",
        "    return text\n",
        "\n",
        "# Tokenisasi\n",
        "def tokenize(text):\n",
        "    return text.split()\n",
        "\n",
        "# Menghapus stopwords\n",
        "def remove_stopwords(tokens):\n",
        "    factory = StopWordRemoverFactory()\n",
        "    stopword = factory.create_stop_word_remover()\n",
        "    return [word for word in tokens if word not in factory.get_stop_words()]\n",
        "\n",
        "# Stemming\n",
        "def stem_words(tokens):\n",
        "    factory = StemmerFactory()\n",
        "    stemmer = factory.create_stemmer()\n",
        "    return [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "# Pipeline preprocessing\n",
        "def preprocess(text):\n",
        "    text = case_folding(text)\n",
        "    tokens = tokenize(text)\n",
        "    tokens = remove_stopwords(tokens)\n",
        "    tokens = stem_words(tokens)\n",
        "    return tokens\n",
        "\n",
        "# Melakukan preprocessing\n",
        "preprocessed_text = preprocess(text)\n",
        "print(\"Hasil Preprocessing:\")\n",
        "print(preprocessed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By9SDIZg9oMM"
      },
      "source": [
        "## SOAL 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnbBfNhh9fWH",
        "outputId": "459f7aad-bac4-4c9d-933b-7879b32a1a80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tabel Frekuensi:\n",
            "       adik  baca  belajar  kakak  komputer  murid  olahraga  tulis\n",
            "Doc 1     1     1        1      1         0      0         1      0\n",
            "Doc 2     0     1        1      0         0      1         0      1\n",
            "Doc 3     0     0        1      1         1      0         0      0\n",
            "\n",
            "Hasil TF-IDF:\n",
            "           adik      baca  belajar     kakak  komputer     murid  olahraga  \\\n",
            "Doc 1  1.098612  0.405465      0.0  0.405465  0.000000  0.000000  1.098612   \n",
            "Doc 2  0.000000  0.405465      0.0  0.000000  0.000000  1.098612  0.000000   \n",
            "Doc 3  0.000000  0.000000      0.0  0.405465  1.098612  0.000000  0.000000   \n",
            "\n",
            "          tulis  \n",
            "Doc 1  0.000000  \n",
            "Doc 2  1.098612  \n",
            "Doc 3  0.000000  \n",
            "\n",
            "Cosine Similarity dengan query 'belajar baca':\n",
            "Doc 1: 0.5143\n",
            "Doc 2: 0.5628\n",
            "Doc 3: 0.2609\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Dokumen-dokumen\n",
        "doc1 = \"adik belajar baca kakak olahraga\"\n",
        "doc2 = \"murid belajar tulis baca\"\n",
        "doc3 = \"kakak belajar komputer\"\n",
        "query = \"belajar baca\"\n",
        "\n",
        "# 1. Membuat tabel frekuensi\n",
        "def create_freq_table(docs):\n",
        "    # Membuat vocabulary\n",
        "    vocab = set()\n",
        "    for doc in docs:\n",
        "        words = doc.split()\n",
        "        vocab.update(words)\n",
        "    vocab = sorted(vocab)\n",
        "\n",
        "    # Membuat tabel frekuensi\n",
        "    freq_table = []\n",
        "    for i, doc in enumerate(docs, 1):\n",
        "        words = doc.split()\n",
        "        freq = {word: words.count(word) for word in vocab}\n",
        "        freq_table.append(freq)\n",
        "\n",
        "    df = pd.DataFrame(freq_table, index=[f'Doc {i}' for i in range(1, len(docs)+1)])\n",
        "    return df\n",
        "\n",
        "docs = [doc1, doc2, doc3]\n",
        "freq_table = create_freq_table(docs)\n",
        "print(\"\\nTabel Frekuensi:\")\n",
        "print(freq_table)\n",
        "\n",
        "# 2. Menghitung TF-IDF\n",
        "def calculate_tfidf(freq_table):\n",
        "    # Menghitung TF\n",
        "    tf = freq_table.copy()\n",
        "\n",
        "    # Menghitung IDF\n",
        "    N = len(freq_table)\n",
        "    idf = {}\n",
        "    for term in freq_table.columns:\n",
        "        df = (freq_table[term] > 0).sum()\n",
        "        idf[term] = math.log(N / df) if df != 0 else 0\n",
        "\n",
        "    # Menghitung TF-IDF\n",
        "    tfidf = tf.copy()\n",
        "    for term in tfidf.columns:\n",
        "        tfidf[term] = tfidf[term] * idf[term]\n",
        "\n",
        "    return tfidf\n",
        "\n",
        "tfidf_table = calculate_tfidf(freq_table)\n",
        "print(\"\\nHasil TF-IDF:\")\n",
        "print(tfidf_table)\n",
        "\n",
        "# 3. Menghitung Cosine Similarity dengan query\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "query_vec = vectorizer.transform([query])\n",
        "\n",
        "cosine_similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()\n",
        "print(\"\\nCosine Similarity dengan query 'belajar baca':\")\n",
        "for i, score in enumerate(cosine_similarities, 1):\n",
        "    print(f\"Doc {i}: {score:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
